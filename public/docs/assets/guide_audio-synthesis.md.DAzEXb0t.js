import{_ as i,c as a,o as t,at as n}from"./chunks/framework.Cnsi11we.js";const p=JSON.parse('{"title":"Audio Synthesis","description":"Real-time audio synthesis capabilities for auditioning maqāmāt and tuning systems","frontmatter":{"title":"Audio Synthesis","description":"Real-time audio synthesis capabilities for auditioning maqāmāt and tuning systems"},"headers":[],"relativePath":"guide/audio-synthesis.md","filePath":"guide/audio-synthesis.md","lastUpdated":1762128859000}'),o={name:"guide/audio-synthesis.md"};function l(s,e,r,d,c,u){return t(),a("div",null,[...e[0]||(e[0]=[n('<div style="display:none;" hidden="true" aria-hidden="true">Are you an LLM? You can read better optimized documentation at /docs/guide/audio-synthesis.md for this page in Markdown format</div><h1 id="audio-synthesis" tabindex="-1">Audio Synthesis <a class="header-anchor" href="#audio-synthesis" aria-label="Permalink to &quot;Audio Synthesis&quot;">​</a></h1><p>DiArMaqAr provides real-time audio synthesis capabilities that allow users to audition precise intonational relationships of maqāmāt and their ajnās across different tuning systems, hearing the theoretical data as actual sound.</p><h2 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;Overview&quot;">​</a></h2><p>Real-time audio synthesis utilizes the Web Audio API through a dedicated SoundContext provider that manages oscillator nodes, envelope control, and MIDI integration. This enables immediate auditory feedback for theoretical concepts, making abstract relationships tangible through sound.</p><h2 id="key-features" tabindex="-1">Key Features <a class="header-anchor" href="#key-features" aria-label="Permalink to &quot;Key Features&quot;">​</a></h2><h3 id="individual-note-playback" tabindex="-1">Individual Note Playback <a class="header-anchor" href="#individual-note-playback" aria-label="Permalink to &quot;Individual Note Playback&quot;">​</a></h3><ul><li>Select any pitch class and hear its precise intonation</li><li>Compare intervals between different notes</li><li>Audition tuning system pitch classes independently of maqām structures</li></ul><h3 id="sequence-synthesis" tabindex="-1">Sequence Synthesis <a class="header-anchor" href="#sequence-synthesis" aria-label="Permalink to &quot;Sequence Synthesis&quot;">​</a></h3><ul><li>Play ascending sequences of maqāmāt or ajnās</li><li>Play descending sequences</li><li>Pattern playback with rhythmic variations</li><li>Demonstrate modal character beyond abstract sequences</li></ul><h3 id="pattern-playback" tabindex="-1">Pattern Playback <a class="header-anchor" href="#pattern-playback" aria-label="Permalink to &quot;Pattern Playback&quot;">​</a></h3><ul><li>Pre-defined melodic patterns (patterns.json)</li><li>Customizable tempo (BPM)</li><li>Rhythmic cells and motifs</li><li>Dynamic control (velocity specifications)</li></ul><h2 id="waveform-support" tabindex="-1">Waveform Support <a class="header-anchor" href="#waveform-support" aria-label="Permalink to &quot;Waveform Support&quot;">​</a></h2><p>The audio system supports multiple periodic and aperiodic waveforms:</p><p><strong>Periodic Waveforms:</strong></p><ul><li>Sine</li><li>Triangle</li><li>Sawtooth</li><li>Square</li></ul><p><strong>Aperiodic Waveforms:</strong></p><ul><li>Multiple custom waveforms (as utilized in Scale Workshop)</li><li>Rich harmonic content options</li><li>Instrument-like timbres</li></ul><h3 id="envelope-control-adsr" tabindex="-1">Envelope Control (ADSR) <a class="header-anchor" href="#envelope-control-adsr" aria-label="Permalink to &quot;Envelope Control (ADSR)&quot;">​</a></h3><p>Precise control over sound articulation:</p><ul><li><strong>Attack</strong>: Initial rise time (default: 0.01s)</li><li><strong>Decay</strong>: Initial fall time (default: 0.20s)</li><li><strong>Sustain</strong>: Sustained level (default: 0.50)</li><li><strong>Release</strong>: Final fall time (default: 0.40s)</li></ul><p>This allows for:</p><ul><li>Realistic musical articulation</li><li>Expressive control</li><li>Comparison between different tunings with consistent articulation</li></ul><h2 id="tuning-system-fidelity" tabindex="-1">Tuning System Fidelity <a class="header-anchor" href="#tuning-system-fidelity" aria-label="Permalink to &quot;Tuning System Fidelity&quot;">​</a></h2><p>The audio synthesis maintains <strong>mathematical precision</strong> when rendering tuning systems:</p><ul><li><strong>Microtonal intervals</strong>: Accurately rendered without artifacts</li><li><strong>Fractional ratios</strong>: Precisely calculated frequencies</li><li><strong>Historical tunings</strong>: Authentic intonational relationships</li><li><strong>No quantization</strong>: Continuous pitch variation preserved</li></ul><h2 id="real-time-processing" tabindex="-1">Real-Time Processing <a class="header-anchor" href="#real-time-processing" aria-label="Permalink to &quot;Real-Time Processing&quot;">​</a></h2><p>The implementation ensures:</p><ul><li><strong>Low latency</strong>: Suitable for real-time interaction</li><li><strong>Responsive interface</strong>: No blocking during audio generation</li><li><strong>Smooth playback</strong>: Continuous sequences without gaps</li><li><strong>Performance optimization</strong>: Efficient Web Audio API usage</li></ul><h2 id="interactive-features" tabindex="-1">Interactive Features <a class="header-anchor" href="#interactive-features" aria-label="Permalink to &quot;Interactive Features&quot;">​</a></h2><h3 id="keyboard-input" tabindex="-1">Keyboard Input <a class="header-anchor" href="#keyboard-input" aria-label="Permalink to &quot;Keyboard Input&quot;">​</a></h3><ul><li>Computer keyboard mapping to pitch classes</li><li>Real-time response to key presses</li><li>Visual feedback on pitch class bar</li><li>Immediate auditory feedback</li></ul><h3 id="midi-integration" tabindex="-1">MIDI Integration <a class="header-anchor" href="#midi-integration" aria-label="Permalink to &quot;MIDI Integration&quot;">​</a></h3><ul><li>External MIDI controller support</li><li>Real-time input processing</li><li>Low-latency response</li><li>Both monophonic and polyphonic capabilities</li></ul><p>See the <a href="/docs/guide/midi-integration/">MIDI Integration Guide</a> for detailed MIDI features.</p><h2 id="research-applications" tabindex="-1">Research Applications <a class="header-anchor" href="#research-applications" aria-label="Permalink to &quot;Research Applications&quot;">​</a></h2><p>Real-time audio synthesis enables:</p><h3 id="comparative-listening" tabindex="-1">Comparative Listening <a class="header-anchor" href="#comparative-listening" aria-label="Permalink to &quot;Comparative Listening&quot;">​</a></h3><ul><li>Compare same maqām across different tuning systems</li><li>Hear how historical tunings affect modal character</li><li>Understand theoretical differences through direct experience</li></ul><h3 id="educational-use" tabindex="-1">Educational Use <a class="header-anchor" href="#educational-use" aria-label="Permalink to &quot;Educational Use&quot;">​</a></h3><ul><li>Students can hear theoretical concepts</li><li>Immediate feedback on learning materials</li><li>Auditory reinforcement of visual/analytical work</li></ul><h3 id="compositional-exploration" tabindex="-1">Compositional Exploration <a class="header-anchor" href="#compositional-exploration" aria-label="Permalink to &quot;Compositional Exploration&quot;">​</a></h3><ul><li>Composers can audition theoretical possibilities</li><li>Discover new harmonic/melodic relationships</li><li>Explore tuning systems before composition</li></ul><h2 id="technical-implementation" tabindex="-1">Technical Implementation <a class="header-anchor" href="#technical-implementation" aria-label="Permalink to &quot;Technical Implementation&quot;">​</a></h2><p>The audio system:</p><ul><li>Uses Web Audio API for browser-based synthesis</li><li>Supports all major browsers (Chrome, Firefox, Safari, Edge)</li><li>Implements graceful degradation for older platforms</li><li>Manages oscillator nodes efficiently</li><li>Handles microtonal frequency calculations precisely</li></ul><h2 id="limitations" tabindex="-1">Limitations <a class="header-anchor" href="#limitations" aria-label="Permalink to &quot;Limitations&quot;">​</a></h2><p>Current implementation focuses on:</p><ul><li>Theoretical representation (not performance practice analysis)</li><li>Synthetic waveforms (not sampled instruments)</li><li>Browser-based synthesis (subject to browser audio limitations)</li></ul><p>Future enhancements could include:</p><ul><li>Audio analysis capabilities for recorded performances</li><li>Integration with digital audio workstations</li><li>Mobile application support</li><li>Expanded waveform library</li></ul><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">​</a></h2><ul><li>Learn about <a href="/docs/guide/midi-integration/">MIDI Integration</a> for advanced control</li><li>Explore <a href="/docs/guide/data-export/">Data Export</a> for external synthesis</li><li>Understand how audio relates to <a href="/docs/guide/tuning-systems/">Tuning Systems</a></li></ul>',53)])])}const m=i(o,[["render",l]]);export{p as __pageData,m as default};
